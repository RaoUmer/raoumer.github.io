<!DOCTYPE html>
<html>
  <head>
    <title>Open Data Resources For Data Science Research: Part-2 </title>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1"
<link rel="apple-touch-icon" sizes="57x57" href="../assets/img/apple-touch-icon-57x57.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="60x60" href="../assets/img/apple-touch-icon-60x60.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="72x72" href="../assets/img/apple-touch-icon-72x72.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="76x76" href="../assets/img/apple-touch-icon-76x76.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="114x114" href="../assets/img/apple-touch-icon-114x114.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="120x120" href="../assets/img/apple-touch-icon-120x120.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="144x144" href="../assets/img/apple-touch-icon-144x144.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="152x152" href="../assets/img/apple-touch-icon-152x152.png?v=wAAv6Wqe6l">
<link rel="apple-touch-icon" sizes="180x180" href="../assets/img/apple-touch-icon-180x180.png?v=wAAv6Wqe6l">
<link rel="manifest" href="../assets/img/manifest.json?v=wAAv6Wqe6l">
<link rel="shortcut icon" href="../assets/img/favicon.ico?v=wAAv6Wqe6l">
<meta name="msapplication-TileColor" content="#e74c3c">
<meta name="msapplication-TileImage" content="/assets/img/mstile-144x144.png?v=wAAv6Wqe6l">
<meta name="msapplication-config" content="/assets/img/browserconfig.xml?v=wAAv6Wqe6l">
<meta name="theme-color" content="#e74c3c">
    <link rel="stylesheet" type="text/css" href="../assets/css/uno-zen.css?v=d88d979280" />
    <link rel="canonical" href="http://raoumer.com/_posts/data_sources_part_2.html" />
    <meta name="referrer" content="origin" />
    
    <meta property="og:site_name" content="Rao Muhammad Umer" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Open Data Resources For Data Science Research: Part-2" />
    <meta property="og:description" content="This blog post is for introducing Open Data Resources for Data Science research." />
    <meta property="og:url" content="u=http://raoumer.com/blog_posts/data_sources.html" />
    <meta property="og:image" content="u=http://raoumer.com/images" />
    <meta property="article:published_time" content="2016-08-24T14:20:00.000Z" />
    <meta property="article:modified_time" content="2016-08-24T08:34:04.543Z" />
    <meta property="article:tag" content="webapp" />
    <meta property="article:tag" content="webapp" />
    <meta property="article:tag" content="webapp" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="" />
    <meta name="twitter:description" content="This blog post is for introducing Data Resources for Open Data Resources for Data Science research." />
    <meta name="twitter:url" content="u=http://raoumer.com/blog_posts/data_sources_part_2.html" />
    <meta name="twitter:image:src" content="u=http://raoumer.com/images" />
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Rao Muhammad Umer",
    "author": {
        "@type": "Person",
        "name": "Rao Muhammad Umer",
        "url": "u=http://raoumer.com/",
        "sameAs": null,
        "description": null
    },
    "headline": "Open Data Resources For Data Science Research",
    "url": "u=http://raoumer.com/blog_posts/data_sources_part_2.html",
    "datePublished": "2017-07-31T14:20:00.000Z",
    "dateModified": "2017-07-31T08:34:04.543Z",
    "image": "u=http://raoumer.com/",
    "keywords": "data sources for data science research: Part-2",
    "description": "This blog post is for introducing Open Data Resources for Data Science Research."
}
    </script>
    <script>
var open_button = '.nav-blog > a'
</script>
<script>
var profile_title = 'Rao Muhammad Umer';
</script>
<script>
var disqus_shortname = 'raomumer';
</script>
<script>
var profile_resume ='Graduate Student';
</script>
  </head>
  <body class="post-template tag-datasources">
    <header id="menu-button" class="expanded">
      <a><i class="icon icon-list"></i></a>
    </header>
    <aside class="cover" style="background: url(../images/cover_6.png) center/cover no-repeat fixed">
  <div class="cover container">
    <div class="profile">
      <a id="avatar-link" title="link to homepage for Rao Muhammad Umer" href="http://raoumer.com/#open">
        <img src="../images/raoumer.png" alt="Rao Umer avatar" class="profile avatar rounded hvr-buzz-out" />
        <h1 id="profile-title">Rao Muhammad Umer</h1>
        <h3 id="profile-resume"></h3>
      </a>

      <hr class="divider long" />
      <p>I&#x27;m a Lecturer in department of Computer Science and IT at The University of Lahore. I blog about Machine Learning, Deep Learning, and Data Science.</p>
      <hr class="divider short" />
      <div class="navigation">
        <div class="profile contact">
          <nav class="navigation left">
  <ul class="links">
      <li class="nav-blog ">
        <a href="http://raoumer.com/#open">Blog</a>
      </li>
      <li class="nav-about nav-current ">
        <a href="http://raoumer.com/about.html">About</a>
      </li>
	<li class="nav-courses nav-current">
	<a href="http://raoumer.com/courses.html">Teaching</a>
      </li>  
      <li class="nav-portfolio nav-current ">
        <a href="http://raoumer.com/portfolio.html">Research</a>
      </li>
      <li class="nav-contact nav-current ">
        <a href="http://raoumer.com/contact.html">Contact</a>
      </li>
  </ul>
</nav>

          
<nav class="navigation right">
  <ul class="social expanded">

  <!-- Twitter -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="http://twitter.com/roumer_swl" title="@raoumer_swl on Twitter">
      <i class='icon icon-social-twitter'></i>
      <span class="label">Twitter</span>
    </a>
  </li>

  <!-- Linkedin -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://www.linkedin.com/in/raomumer" title="raoumer on LinkedIn">
      <i class='icon icon-social-linkedin'></i>
      <span class="label">Linkedin</span>
    </a>
  </li>

  <!-- Github -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="https://github.com/RaoUmer" title="raoumer on Github">
      <i class='icon icon-social-github'></i>
      <span class="label">Github</span>
    </a>
  </li>

  <!-- E-mail -->
  <li class="social item hvr-grow-rotate">
    <a rel="me" target="blank" href="mailto:engr.raoumer943@gmail.com" title="send me an email">
      <i class='icon icon-mail'></i>
      <span class="label">Email</span>
    </a>
  </li>

  </ul>
</nav>

        </div>
      </div>
    </div>
  </div>
</aside>
    <main>
      <section id="search-results"></section>
      <section class="content">
        

  <article class="post tag-datasets tag-ML tag-DL tag-DS">
    <header>
      <div class="post meta">
        <time datetime="31 July 2017">31 July 2017</time>
        <span class="post tags">in <a href="../blog_posts/data_sources_part_2.html">Open Data Resources For Data Science Research: Part-2</a> </span>


        <span class="post reading-time"> ~ <span></span> read.</span>
      </div>
      <a alt="Tweet 'Open Data Resources For Data Science Research: Part-2'" href="https://twitter.com/intent/tweet?text=Open%20Data%20Resources%20for%20Data%20Science%20Research%20%C2%BB&amp;hashtags=&amp;url=http://raoumer.com/blog_posts/data_sources_part_2.html">
        <img id="post-image" src="../images/ds.jpg" alt="Open Data Resources For Data Science Research: Part-2">
		<h1 class="icon-reverse icon-social-twitter-post" id="post-title">Open Data Resources For Data Science Research: Part-2</h1>
      </a>
    </header>

    <div id="post-content" class="post tag-webapp tag-github tag-flask tag-heroku">

	<p> This blog post is continuing the pervious <a href="http://raoumer.com/blog_posts/data_sources.html">post on open datasets</a>. Here are more cool public open data sources you can use for your projects related to Data Science, Machine Learning and Deep Learning research:</p>
	<ul>
	
	<li> <strong> ImageNet Dataset</strong>
	<ul>
	<li><a href="http://image-net.org/index"> <strong>ImageNet Dataset:</strong></a>  ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. </li>
	</ul>
	</li>
	<li> <strong> Open Data for Deep Learning</strong>
	<ul>
	<li><a href="https://deeplearning4j.org/opendata"> <strong>Open Data for Deep Learning:</strong></a>  Here you’ll find an organized list of interesting, high-quality datasets for machine learning and deep learning research. </li>
	</ul>
	</li>
	<li> <strong> List of datasets for machine learning research</strong>
	<ul>
	<li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research"> <strong>List of datasets for machine learning research:</strong></a>  These datasets are used for machine learning research and have been cited in peer-reviewed academic journals and other publications. </li>
	</ul>
	</li>
	<li> <strong> NEXET Dataset</strong>
	<ul>
	<li><a href="https://www.getnexar.com/challenge-2/"> <strong>NEXET Dataset:</strong></a> The Nexar dataset is a massive set consisting of 50,000 images from all over the world with bounding box annotations of the rear of vehicles collected from a variety of locations, lighting, and weather conditions. We are releasing this dataset to you, our challengers, to empower you to build a truly smart collision prevention system that can work extremely well anywhere and at any time. </li>
	</ul>
	</li>
	<li> <strong> Kinect Gesture Data Set</strong>
	<ul>
	<li><a href="http://research.microsoft.com/en-us/um/cambridge/projects/msrc12/"> <strong>Kinect Gesture Data Set:</strong></a> The Microsoft Research Cambridge-12 Kinect gesture data set consists of sequences of human movements, represented as body-part locations, and the associated gesture to be recognized by the system. </li>
	</ul>
	</li>
	<li> <strong> MSRA-CFW: Data Set of Celebrity Faces on the Web</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/research/project/msra-cfw-data-set-of-celebrity-faces-on-the-web/"> <strong>Data Set of Celebrity Faces on the Web:</strong></a> The dataset includes image URLs for 202792 faces. The labels of the faces are automatically generated by the algorithm, with high accuracy. To facilitate downloading the images, we provide a number of URLs for the near-duplicates of each face. Besides, the thumbnail images and facial features(LBP) are also provided for visualization and benchmarking purposes. </li>
	</ul>
	</li>	
	<li> <strong> Image Cropping Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52457"> <strong>Image Cropping Dataset:</strong></a> The Image Cropping Dataset contains the cropping parameters for 1000 images that were manually cropped by an experienced photographer. </li>
	</ul>
	</li>
	<li> <strong> Visual Question Generation dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=53670"> <strong>Visual Question Generation dataset:</strong></a> We introduce this dataset in order to support the novel task of Visual Question Generation (VQG), where, given an image, the system should ‘ask a natural and engaging question’. This dataset can be used to support research on common sense reasoning and compute-human conversational systems. </li>
	</ul>
	</li>
	<li> <strong> Smart Selection Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52526"> <strong>Smart Selection Dataset:</strong></a> Smart selection is the task of predicting the span of text that a user intended to select after they touched on a single word on a touch-enabled device.  </li>
	</ul>
	</li>
	<li> <strong> MSR Demosaicing Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52535"> <strong>MSR Demosaicing Dataset:</strong></a> The Microsoft Research Cambridge demosaicing data set consists of set of raw images, and their downscaled versions which can be used for learning and evaluating demosaicing (and possibly other tasks like denoising), both in linear-space and color-space. </li>
	</ul>
	</li>
	<li> <strong> Abstract Scene Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52035"> <strong>Abstract Scene Dataset:</strong></a> This dataset contains clip art related to the academic paper Bringing Semantics Into Focus Using Visual Abstraction. </li>
	</ul>
	</li>
	<li> <strong> FingerPaint Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52288"> <strong>FingerPaint Dataset:</strong></a> The FingerPaint Dataset contains video-sequences of several individuals performing hand gestures, as captured by a depth camera. </li>
	</ul>
	</li>
	<li> <strong> Microsoft Document Aboutness Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52295"> <strong>Microsoft Document Aboutness Dataset:</strong></a> The Microsoft Document Aboutness Dataset consists of randomly sampled URLs (from a HEAD and TAIL distribution), all entities recognized in those documents, and a relevance assessment for each entity/URL pair as to whether or not the entity is salient to the content of the URL.</li>
	</ul>
	</li>
	<li> <strong> MSR Abstractive Text Compression Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54262"> <strong>MSR Abstractive Text Compression Dataset:</strong></a> This dataset contains sentences and short paragraphs with corresponding shorter (compressed) versions. There are up to five compressions for each input text, together with quality judgements of their meaning preservation and grammaticality.</li>
	</ul>
	</li>
	<li> <strong> WebQuestions Semantic Parses Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52763"> <strong>WebQuestions Semantic Parses Dataset:</strong></a> The WebQuestionsSP dataset is released as part of our ACL-2016 paper “The Value of Semantic Parse Labeling for Knowledge Base Question Answering” [Yih, Richardson, Meek, Chang & Suh, 2016], in which we evaluated the value of gathering semantic parses, vs. answers, for a set of questions that originally comes from WebQuestions [Berant et al., 2013].</li>
	</ul>
	</li>
	<li> <strong>Election 2012 Tweet ID dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52598"> <strong>Election 2012 Tweet ID dataset:</strong></a> This data set identifies 38M tweets collected for the analysis of social media messages related to the 2012 U.S.</li>
	</ul>
	</li>
	<li> <strong> MSR 3D Video Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52358"> <strong>MSR 3D Video Dataset:</strong></a> This data includes a sequence of 100 images captured from 8 cameras showing the breakdancing and ballet scenes from the paper “High-quality video view interpolation using a layered representation”, Zitnick et al., SIGGRAPH 2004.</li>
	</ul>
	</li>
	<li> <strong> MSR GPS Privacy Dataset 2009</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54965"> <strong>MSR GPS Privacy Dataset 2009:</strong></a> The table below contains pointers to text files with GPS data taken in the region of Seattle, Washington USA. Each file contains data from one of 21 volunteers who carried a GPS logger with them for approximately eight weeks in the fall of 2009. This set of 21 volunteers is a subset of 37 people who participated in the survey.</li>
	</ul>
	</li>
	<li> <strong>FB15K-237 Knowledge Base Completion Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52312"> <strong>FB15K-237 Knowledge Base Completion Dataset:</strong></a> This dataset contains knowledge base relation triples and textual mentions of Freebase entity pairs, as used in the work published in (Toutanova and Chen CVSM-2015) and (Toutanova et al).</li>
	</ul>
	</li>
	<li> <strong> Avatar Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52026"> <strong>Avatar Dataset:</strong></a> MRS introduce a new corpus of descriptions of Xbox avatars created by actual gamers. </li>
	</ul>
	</li>
	<li> <strong>Diverse Algebra Word Problem Dataset with Derivation Annotations</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52628"> <strong>Diverse Algebra Word Problem Dataset with Derivation Annotations:</strong></a> This dataset provides training and testing examples for solving algebra word problems automatically.</li>
	</ul>
	</li>
	<li> <strong>NCI-PID-PubMed Genomics Knowledge Base Completion Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54054"> <strong>NCI-PID-PubMed Genomics Knowledge Base Completion Dataset:</strong></a> This dataset includes a database of regulation relationships among genes and corresponding textual mentions of pairs of genes in PubMed article abstracts.</li>
	</ul>
	</li>
	<li> <strong> Longitudinal Tweet ID dataset for a selection of Health, Social, and Business Experiences</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54927"> <strong>Longitudinal Tweet ID dataset for a selection of Health, Social, and Business Experiences:</strong></a> This data set consists of the tweet IDs collected for the propensity-score analysis of longitudinal social media messages posted by people who mention specific health, social and business domains. This data set accompanies the paper, “Distilling the Outcomes of Personal Experiences: A Propensity-scored Analysis of Social Media.</li>
	</ul>
	</li>
	<li> <strong>Dataset for Inferring Missing Entity Type Instances for Knowledge Base Completion</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52589"> <strong>Dataset for Inferring Missing Entity Type Instances for Knowledge Base Completion:</strong></a> This is a dataset that can be used for training and evaluating knowledge base completion approaches for inferring missing entity type instances.</li>
	</ul>
	</li>
	<li> <strong>Tweet Entity Linking Dataset: IE-driven and IR-driven sets</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52443"> <strong>Tweet Entity Linking Dataset: IE-driven and IR-driven sets:</strong></a> In this dataset, we release the labeled data for people to evaluate and compare entity linking systems on tweets.</li>
	</ul>
	</li>
	<li> <strong> Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54592"> <strong>Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences Dataset:</strong></a> This is the data released with the CHI 2017 paper: As We May Ink? Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences. It contains the 493 entries of a diary study with 26 participants on their use of analog pen and the 178 entries of a follow-up diary study with 30 participants on their use of digital pen.</li>
	</ul>
	</li>
	<li> <strong>Optical Data</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54267"> <strong>Optical Data:</strong></a> This dataset includes 14 months of optical data from Microsoft’s wide-area backbone network in North America.</li>
	</ul>
	</li>
	<li> <strong>Learning from Explicit and Implicit Supervision Jointly For Algebra Word Problems</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=53878"> <strong>Learning from Explicit and Implicit Supervision Jointly For Algebra Word Problems:</strong></a> This is a public release of the dataset corresponding the paper "Learning from Explicit and Implicit Supervision Jointly For Algebra Word Problems" that will appear in EMNLP 2016.</li>
	</ul>
	</li>
	<li> <strong>Microsoft Research Sequential Question Answering (SQA) Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=54253"> <strong>Microsoft Research Sequential Question Answering (SQA) Dataset:</strong></a> The SQA dataset was created to explore the task of answering sequences of inter-related questions on HTML tables. It has 6,066 sequences with 17,553 questions in total.</li>
	</ul>
	</li>
	<li> <strong>Microsoft Cognitive Toolkit Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/cognitive-toolkit/"> <strong>Microsoft Cognitive Toolkit Dataset:</strong></a> The Microsoft Cognitive Toolkit empowers you to harness the intelligence within massive datasets through deep learning by providing uncompromised scaling, speed and accuracy with commercial-grade quality and compatibility with the programming languages and algorithms you already use.</li>
	</ul>
	</li>
	<li> <strong>GeoLife GPS Trajectories Dataset</strong>
	<ul>
	<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52367"> <strong>GeoLife GPS Trajectories Dataset:</strong></a> This GPS trajectory dataset was collected in (Microsoft Research Asia) Geolife project by 182 users in a period of over three years (from April 2007 to August 2012).</li>
	</ul>
	</li>
	<li> <strong>Wikipedia Biography Dataset</strong>
	<ul>
	<li><a href="https://github.com/DavidGrangier/wikipedia-biography-dataset"> <strong>Wikipedia Biography Dataset:</strong></a> This dataset gathers 728,321 biographies from wikipedia. It aims at evaluating text generation algorithms.</li>
	</ul>
	</li>
	<li> <strong>SpineWeb Dataset</strong>
	<ul>
	<li><a href="http://spineweb.digitalimaginggroup.ca/spineweb/index.php?n=Main.Datasets"> <strong>SpineWeb Dataset:</strong></a> This dataset are collected for Research on Spine Imaging and Image Analysis.</li>
	</ul>
	</li>
	<li> <strong>Stack Exchange Dataset</strong>
	<ul>
	<li><a href="https://archive.org/details/stackexchange"> <strong>Stack Exchange Dataset:</strong></a> This is an anonymized dump of all user-contributed content on the Stack Exchange network. Each site is formatted as a separate archive consisting of XML files zipped via 7-zip using bzip2 compression. Each site archive includes Posts, Users, Votes, Comments, PostHistory and PostLinks.</li>
	</ul>
	</li>
	<li> <strong>The Twitter Stream Grab Dataset</strong>
	<ul>
	<li><a href="https://archive.org/details/twitterstream"> <strong>The Twitter Stream Grab Dataset:</strong></a> A simple collection of JSON grabbed from the general twitter stream, for the purposes of research, history, testing and memory.</li>
	</ul>
	</li>
	<li> <strong>StarData</strong>
	<ul>
	<li><a href="https://github.com/TorchCraft/StarData"> <strong>StarData Dataset:</strong></a> We release the largest StarCraft: Brood War replay dataset yet, with 65646 games. The full dataset after compression is 365 GB, 1535 million frames, and 496 million player actions. The entire frame data was dumped out at 8 frames per second. We made a big effort to ensure this dataset is clean and has mostly high quality replays. You can access it with TorchCraft in C++, Python, and Lua. The replays are in an AWS S3 bucket at s3://stardata.</li>
	</ul>
	</li>
	<li> <strong>Phrasal Recognition Dataset</strong>
	<ul>
	<li><a href="http://vision.cs.uiuc.edu/phrasal/"> <strong>Phrasal Recognition Dataset:</strong></a> This dataset contains 8 object categories from Pascal VOC that are suitable for studying the interactions between objects.</li>
	</ul>
	</li>
	<li> <strong>UIUC Pascal Sentence Dataset </strong>
	<ul>
	<li><a href="http://vision.cs.uiuc.edu/pascal-sentences/"> <strong>UIUC Pascal Sentence Dataset </strong></a> </li>
	</ul>
	</li>
	<li> <strong>Cross Category Object Recognition Dataset (CORE) </strong>
	<ul>
	<li><a href="http://vision.cs.uiuc.edu/CORE/"> <strong>Cross Category Object Recognition Dataset:</strong></a> The CORE dataset is intended to help learn more detailed models and for exploring cross-category generalization in object recognition.</li>
	</ul>
	</li>
	<li> <strong>Attribute Dataset (aPascal, aYahoo) </strong>
	<ul>
	<li><a href="http://vision.cs.uiuc.edu/attributes/"> <strong>Attribute Dataset (aPascal, aYahoo):</strong></a> There are three components to the dataset:<br>
Annotations: The attribute annotations for the aPascal train and test sets, and aYahoo test set.<br>
aYahoo images: Our images collected from Yahoo <br>
aPascal images: These are the images from the Pascal VOC 2008. </li>
	</ul>
	</li>

	</ul>
	
	<p><em><strong>Note:</strong> If you know about any other dataset for triggering data science, machine learning and deep learning research, which is not listed here, please, feel free to comment below with downloadable link. I would like to add it in above list.</em></p>
    <br>
	    <!-- Flag counter -->
	     <img src="http://s05.flagcounter.com/count2/8CG/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"> 
	    
	    <br>
	<!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
	/* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//github.us15.list-manage.com/subscribe/post?u=1c7ce47851d73e8c2a4272286&amp;id=aeafba074a" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<h2>Subscribe to my mailing list</h2>
<div class="indicates-required"><span class="asterisk">*</span> indicates required</div>
<div class="mc-field-group">
	<label for="mce-EMAIL">Email Address  <span class="asterisk">*</span>
</label>
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_1c7ce47851d73e8c2a4272286_aeafba074a" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
	    
	    <div class="post related">

        <a rel="next" id="next-btn" class="btn small square" href="../blog_posts/data_sources.html"> Open Data Resources for Data Science Research - Part-1 →</a>
    </div>

	 </div>


    <footer class="post comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
  (function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + window.disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</footer>

  </article>


<script type="text/javascript"  
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>  

        <footer>
  <span class="copyright">
    &copy; 2016 Rao Muhammad Umer. All rights reserved. Built with <a href="https://github.com/Kikobeats/uno-zen" target="_blank">Uno Zen</a> theme.
  </span>
</footer>
      </section>
    </main>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
	<script>jQuery = Zepto</script>
    <script src="../assets/js/uno-zen.js?v=d88d979280" type="text/javascript" charset="utf-8"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="javascripts/analytics.js"> </script>
  </body>
</html>
